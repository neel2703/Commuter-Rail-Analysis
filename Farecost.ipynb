{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries for Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Seasonal Fare Data by Year\n",
    " This code reads fare product data for different seasons and years from individual text files into a dictionary of DataFrames (`fares_data`). Each key represents a specific season and year (e.g., `fares_Spring2023`), and the corresponding value is a DataFrame containing fare data for that period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2023, 2024]\n",
    "seasons = ['Spring', 'Summer', 'Fall', 'Winter']\n",
    "fares_data = {}\n",
    "\n",
    "for year in years:\n",
    "    for season in seasons:\n",
    "        \n",
    "        file_path = f'/Users/bhuvan/Documents/VS code/DS701 project/Datasets/{season}{year}/fare_products.txt'\n",
    "        if file_path != '/Users/bhuvan/Documents/VS code/DS701 project/Datasets/Winter2024/fare_products.txt':\n",
    "            fares_data[f'fares_{season}{year}'] = pd.read_csv(file_path, delimiter=',')\n",
    "            fares_data[f'fares_{season}{year}']['season'] = f'{season}'\n",
    "            fares_data[f'fares_{season}{year}']['year'] = f'{year}'\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Seasonal Fare Rules Data by Year\n",
    "\n",
    "This code loads fare rules data from text files for different seasons and years into a dictionary of DataFrames (`fares_rules_data`). Each key in the dictionary represents a unique season and year (e.g., `fares_rules_Spring2023`), allowing for organized and accessible seasonal data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2023, 2024]\n",
    "seasons = ['Spring', 'Summer', 'Fall', 'Winter']\n",
    "fares_rules_data = {}\n",
    "\n",
    "for year in years:\n",
    "    for season in seasons:\n",
    "        \n",
    "        file_path = f'/Users/bhuvan/Documents/VS code/DS701 project/Datasets/{season}{year}/fare_leg_rules.txt'\n",
    "        if file_path != '/Users/bhuvan/Documents/VS code/DS701 project/Datasets/Winter2024/fare_leg_rules.txt':\n",
    "            fares_rules_data[f'fares_rules_{season}{year}'] = pd.read_csv(file_path, delimiter=',')\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_data = pd.read_csv('/Users/bhuvan/Documents/DS701 project/Datasets/Spring2023/routes.txt', delimiter=',')\n",
    "routes_data = routes_data[routes_data['route_desc'] == 'Commuter Rail']\n",
    "routes_data = routes_data.dropna(axis=1, how='any')\n",
    "routes_data = routes_data.drop('route_text_color', axis=1, inplace=False)\n",
    "#routes_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Seasonal Fare DataFrames\n",
    "\n",
    "This code combines all the seasonal fare DataFrames from the `fares_data` dictionary into a single DataFrame (`combined_fares_df`) and provides an overview of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fares_df = pd.concat(fares_data.values(), ignore_index=True)\n",
    "combined_fares_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Seasonal Fare Rules DataFrames\n",
    "\n",
    "This code merges all the seasonal fare rules DataFrames from the `fares_rules_data` dictionary into a single DataFrame (`combined_fares_rules_df`) and provides a summary of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fares_rules_df = pd.concat(fares_rules_data.values(), ignore_index=True)\n",
    "combined_fares_rules_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unnecessary Columns from Combined Fare Rules DataFrame\n",
    "\n",
    "This code removes specific columns from the `combined_fares_rules_df` DataFrame and displays a summary of the updated DataFrame structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fares_rules_df = combined_fares_rules_df.drop(columns=['transfer_only', 'from_timeframe_group_id', 'to_timeframe_group_id'])\n",
    "combined_fares_rules_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Combined Fare and Fare Rules DataFrames\n",
    "\n",
    "This code merges the `combined_fares_df` and `combined_fares_rules_df` DataFrames into a single DataFrame (`combined_fare_result`) based on the `fare_product_id` column and provides a brief summary of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fare_result = pd.merge(combined_fares_df, combined_fares_rules_df, on='fare_product_id', how='inner')\n",
    "combined_fare_result = pd.merge(combined_fare_result, routes_data, on='network_id', how='left')\n",
    "combined_fare_result = combined_fare_result.drop(columns=['agency_id', 'route_type', 'route_sort_order', 'route_color'])\n",
    "combined_fare_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Combined Fare Data for Commuter Rail\n",
    "\n",
    "This code filters the `combined_fare_result` DataFrame to include only rows related to the 'commuter_rail' and 'cape_flyer' networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fare_result_CR = combined_fare_result[combined_fare_result['network_id'].isin(['commuter_rail', 'cape_flyer'])]\n",
    "combined_fare_result_CR.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fare_result_CR_cash = combined_fare_result_CR[combined_fare_result_CR['fare_media_id'] == 'cash']\n",
    "combined_fare_result_CR_cash_1a = combined_fare_result_CR[combined_fare_result_CR['from_area_id'] == 'area_commuter_rail_zone_1a']\n",
    "combined_fare_result_CR_cash_1a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fare_result_CR_cash_1a_drop = combined_fare_result_CR_cash_1a.drop_duplicates()\n",
    "combined_fare_result_CR_cash_1a_drop = combined_fare_result_CR_cash_1a_drop[combined_fare_result_CR_cash_1a_drop['fare_media_id'] == 'cash']\n",
    "combined_fare_result_CR_cash_1a_drop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fare_result_CR_cash_1a_drop_group = combined_fare_result_CR_cash_1a_drop.groupby(['year', 'season', 'route_id', 'to_area_id']).size().reset_index(name='count')\n",
    "combined_fare_result_CR_cash_1a_drop_group.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary specifying the `to_area_id` you want to keep for each `line_id`\n",
    "to_area_id_mapping = {\n",
    "    'line-CapeFlyer': 'area_cf_zone_hyannis',  # example\n",
    "    'line-Fairmount': 'area_commuter_rail_zone_2',  # example\n",
    "    'line-Fitchburg': 'area_commuter_rail_zone_8',\n",
    "    'line-Worcester': 'area_commuter_rail_zone_8',\n",
    "    'line-Franklin': 'area_commuter_rail_zone_6',\n",
    "    'line-Greenbush': 'area_commuter_rail_zone_6',\n",
    "    'line-Haverhill': 'area_commuter_rail_zone_7',\n",
    "    'line-Kingston': 'area_commuter_rail_zone_8',\n",
    "    'line-Lowell': 'area_commuter_rail_zone_6',\n",
    "    'line-Middleborough': 'area_commuter_rail_zone_8',\n",
    "    'line-Needham': 'area_commuter_rail_zone_2',\n",
    "    'line-Newburyport': 'area_commuter_rail_zone_8',\n",
    "    'line-Providence': 'area_commuter_rail_zone_10',\n",
    "}\n",
    "#combined_fare_result_CR_cash_1a_drop['to_area_id'] = combined_fare_result_CR_cash_1a_drop['line_id'].map(to_area_id_mapping).fillna(combined_fare_result_CR_cash_1a_drop['to_area_id'])\n",
    "filtered_df = combined_fare_result_CR_cash_1a_drop[\n",
    "    combined_fare_result_CR_cash_1a_drop.apply(\n",
    "        lambda row: row['to_area_id'] == to_area_id_mapping.get(row['line_id'], row['to_area_id']),\n",
    "        axis=1\n",
    "    )\n",
    "]\n",
    "# Perform a left merge to bring in the 'amount' column from combined_fare_result_CR_cash_1a_drop\n",
    "# Ensure only 'amount' column is brought over to avoid any duplication of columns\n",
    "merged_df = filtered_df.merge(\n",
    "    combined_fare_result_CR_cash_1a_drop[['to_area_id', 'amount']],\n",
    "    on='to_area_id',\n",
    "    suffixes=('', '_new'),\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Update the 'amount' column in filtered_df to match the values from combined_fare_result_CR_cash_1a_drop\n",
    "merged_df['amount'] = merged_df['amount_new'].combine_first(merged_df['amount'])\n",
    "\n",
    "# Drop the 'amount_new' column as it was only needed for updating\n",
    "merged_df = merged_df.drop(columns=['amount_new'])\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "# Now merged_df has the updated 'amount' values in the 'amount' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_ppt = merged_df[['route_id', 'amount']]\n",
    "merged_df_ppt = merged_df_ppt.drop_duplicates()\n",
    "merged_df_ppt = merged_df_ppt.reset_index(drop=True)\n",
    "merged_df_ppt = merged_df_ppt.sort_values(by='amount', ascending=False)\n",
    "merged_df_ppt = merged_df_ppt.reset_index(drop=True)\n",
    "merged_df_ppt['amount'] = merged_df_ppt['amount'].apply(lambda x: f\"${x:.2f}\")\n",
    "merged_df_ppt.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Average Fare Cost Changes Over Time for Commuter Rail\n",
    "\n",
    "This code groups the filtered fare data by season, year, and fare product name, calculates the average fare amount, and visualizes fare changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fare_result_CR_group = combined_fare_result_CR_cash.groupby(['season', 'year', 'fare_product_name'])['amount'].mean().reset_index()\n",
    "sns.lineplot(data=combined_fare_result_CR_group, x='season', y='amount', hue='year')\n",
    "plt.title('Average Fare Cost Changes Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named 'df'\n",
    "merged_df['season_year'] = merged_df['season'] + ' ' + merged_df['year'].astype(str)\n",
    "\n",
    "# Sort the data by 'year' and 'season' to ensure the timeline is correctly ordered\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "merged_df['season'] = pd.Categorical(merged_df['season'], categories=season_order, ordered=True)\n",
    "df = merged_df.sort_values(['year', 'season'])\n",
    "\n",
    "# Get the unique route_ids\n",
    "route_ids = merged_df['route_id'].unique()\n",
    "\n",
    "# Set up a color map for distinguishing different route IDs\n",
    "colors = plt.cm.tab20.colors\n",
    "\n",
    "# Loop through each route_id and plot\n",
    "for i, route_id in enumerate(route_ids):\n",
    "    # Filter the data for the current route_id\n",
    "    route_data = merged_df[merged_df['route_id'] == route_id]\n",
    "    \n",
    "    # Create a new figure for each route\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Scatter plot with x as season-year and y as amount\n",
    "    plt.scatter(route_data['season_year'], route_data['amount'], color=colors[i % len(colors)], label=route_id)\n",
    "    \n",
    "    # Line plot to connect the points\n",
    "    plt.plot(route_data['season_year'], route_data['amount'], color=colors[i % len(colors)], linestyle='-', marker='o')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Season & Year\")\n",
    "    plt.ylabel(\"Amount\")\n",
    "    plt.title(f\"Fare Amount Over Time for Route ID: {route_id}\")\n",
    "    \n",
    "    # Rotate x-axis labels for readability\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add legend and grid\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
